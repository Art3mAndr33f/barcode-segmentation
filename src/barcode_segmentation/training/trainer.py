#!/usr/bin/env python3
"""
Trainer –º–æ–¥—É–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç PyTorch Lightning –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å MLflow 
–¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É —á–µ—Ä–µ–∑ Hydra.
"""

import logging
import os
from pathlib import Path
from typing import Any, Dict, Optional, Union

import hydra
import mlflow
import pytorch_lightning as pl
from omegaconf import DictConfig, OmegaConf
from pytorch_lightning.callbacks import (
    EarlyStopping,
    LearningRateMonitor,
    ModelCheckpoint,
)
from pytorch_lightning.loggers import MLFlowLogger

from barcode_segmentation.data.dataloader import BarcodeDataModule
from barcode_segmentation.models.lightning_module import BarcodeLightningModule
from barcode_segmentation.training.evaluator import ModelEvaluator
from barcode_segmentation.utils.metrics import compute_metrics

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BarcodeTrainer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥–æ–≤.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç PyTorch Lightning –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è 
    —Å MLflow –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É —á–µ—Ä–µ–∑ Hydra.
    
    Attributes:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        model: –ú–æ–¥–µ–ª—å Lightning
        data_module: –ú–æ–¥—É–ª—å –¥–∞–Ω–Ω—ã—Ö Lightning
        trainer: Trainer Lightning
        evaluator: –ö–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞.
        
        Args:
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self.config = None
        self.model = None
        self.data_module = None
        self.trainer = None
        self.evaluator = None
        self.config_path = config_path
        
    def run(self, config_path: Optional[str] = None) -> None:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è.
        
        Args:
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º config_path –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –∏–∑ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        config_path = config_path or self.config_path or "configs/train.yaml"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ Hydra
        with hydra.initialize_config_module(config_module="configs"):
            self.config = hydra.compose(config_name=Path(config_path).stem)
            
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_path}")
        
        try:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
            self._setup_environment()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            self._initialize_data_module()
            self._initialize_model()
            self._initialize_trainer()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            self._train()
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
            self._evaluate()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self._save_results()
            
            logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            raise
            
    def _setup_environment(self) -> None:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        pl.seed_everything(self.config.seed, workers=True)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º MLflow
        mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)
        mlflow.set_experiment(self.config.mlflow.experiment_name)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_dir = Path(self.config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        model_dir = Path(self.config.model_dir)
        model_dir.mkdir(parents=True, exist_ok=True)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:\n{OmegaConf.to_yaml(self.config)}")
        
    def _initialize_data_module(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è –¥–∞–Ω–Ω—ã—Ö")
        
        # –°–æ–∑–¥–∞–µ–º data module
        self.data_module = BarcodeDataModule(
            data_dir=self.config.data_dir,
            batch_size=self.config.training.batch_size,
            num_workers=self.config.training.num_workers,
            train_transforms=self.config.data.train_transforms,
            val_transforms=self.config.data.val_transforms
        )
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self.data_module.prepare_data()
        self.data_module.setup(stage="fit")
        
        logger.info(f"‚úì Data module –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"‚úì –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(self.data_module.train_dataset)}")
        logger.info(f"‚úì –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(self.data_module.val_dataset)}")
        
    def _initialize_model(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏."""
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏")
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = BarcodeLightningModule(
            model_config=self.config.model,
            learning_rate=self.config.training.learning_rate,
            weight_decay=self.config.training.weight_decay,
            lr_scheduler=self.config.training.scheduler
        )
        
        logger.info("‚úì –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
    def _initialize_trainer(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞ PyTorch Lightning."""
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–≥–µ—Ä MLflow
        mlf_logger = MLFlowLogger(
            experiment_name=self.config.mlflow.experiment_name,
            tracking_uri=self.config.mlflow.tracking_uri
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        mlf_logger.log_hyperparams(self.config)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º callbacks
        callbacks = [
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ learning rate
            LearningRateMonitor(logging_interval="step"),
            
            # Checkpoint
            ModelCheckpoint(
                dirpath=os.path.join(self.config.model_dir, "checkpoints"),
                filename="{epoch}-{val_loss:.4f}",
                monitor=self.config.checkpoint.monitor,
                mode=self.config.checkpoint.mode,
                save_top_k=self.config.checkpoint.save_top_k,
                every_n_epochs=self.config.checkpoint.every_n_epochs,
            ),
            
            # Early stopping
            EarlyStopping(
                monitor=self.config.early_stopping.monitor,
                patience=self.config.early_stopping.patience,
                mode=self.config.early_stopping.mode,
            )
        ]
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        self.trainer = pl.Trainer(
            max_epochs=self.config.training.max_epochs,
            val_check_interval=self.config.training.val_check_interval,
            accelerator=self.config.training.accelerator,
            devices=self.config.training.devices,
            precision=self.config.training.precision,
            gradient_clip_val=self.config.training.gradient_clip_val,
            logger=mlf_logger,
            callbacks=callbacks,
            log_every_n_steps=self.config.logging.log_every_n_steps,
            default_root_dir=self.config.output_dir,
        )
        
        logger.info("‚úì –¢—Ä–µ–Ω–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
    def _train(self) -> None:
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è."""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        self.trainer.fit(self.model, self.data_module)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º best checkpoint
        best_model_path = self.trainer.checkpoint_callback.best_model_path
        if best_model_path:
            logger.info(f"‚úì –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {best_model_path}")
        
    def _evaluate(self) -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        logger.info("üìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º evaluator
        self.evaluator = ModelEvaluator(
            model=self.model,
            data_module=self.data_module,
            config=self.config
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ
        metrics = self.evaluator.evaluate()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ MLflow
        with mlflow.start_run():
            for name, value in metrics.items():
                mlflow.log_metric(name, value)
        
        logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏: {metrics}")
        return metrics
        
    def _save_results(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è."""
        logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è")
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å –º–æ–¥–µ–ª–∏
        final_model_path = Path(self.config.model_dir) / "final_model.pt"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model.save_model(str(final_model_path))
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ MLflow
        with mlflow.start_run():
            mlflow.pytorch.log_model(
                self.model.model,
                "model",
                conda_env={
                    "name": "barcode_segmentation",
                    "channels": ["pytorch", "conda-forge"],
                    "dependencies": [
                        "python>=3.8",
                        "pytorch>=2.0.0",
                        "torchvision>=0.15.0",
                        "detectron2",
                    ]
                }
            )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config_path = Path(self.config.output_dir) / "config.yaml"
        with open(config_path, "w") as f:
            f.write(OmegaConf.to_yaml(self.config))
            
        logger.info(f"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
        logger.info(f"‚úì –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_path}")


def main() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    import argparse
    
    parser = argparse.ArgumentParser(description="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥–æ–≤")
    parser.add_argument("--config", type=str, default="configs/train.yaml", help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    
    args = parser.parse_args()
    
    trainer = BarcodeTrainer()
    trainer.run(args.config)


if __name__ == "__main__":
    main()